MapReduce 是一个分布式运算程序的编程框架，是用户开发基于“Hadoopd 数据分析应用”	的核心框架
MapReduce核心功能是将用户编写的逻辑代码和自带默认组件整合成一个完整的分布式运算程序，并发的运行在hadoop集群上 

Map阶段
1)读数据，并按行处理
2)按空格切分行内单词
3)KV键值对（单词，1)
4)将所有的KV键值对中的单词，按照单词首字母分成2个分区溢写到磁盘

1、Mapper阶段
(1)用户自定义Mapper要继承自己的父类
(2)Mapper的输入数据是KV对的形式（KV类型可以自己定义)
(3)Mapper中的业务逻辑写在Map()方法中
(4)Mapper的输出数据是KV对的形式（KV的类型可自定义)
(5)map()方法(MapTask进程)对每一个<k,v>调用一次
2、Reduce 阶段
(1)用户自定义的Reducer要继承自己的父类
(2)Reducer的输入数据类型对应Mapper的输出数据类型也是K，V
(3)Reduce的业务逻辑写在reduce()方法中
(4)ReduceTask进程对每一个相同K的<k，V>组调用一次reduce()方法
3、Driver阶段
相当于YARN集群的客户端，用于提交我们整个程序到集群，提交的是封装MapReduce程序相关运行参数的Job对象




1)MapReduce 运算程序一般需要分成2个阶段Map阶段和Reduce阶段
2)Map阶段的并发MapTask完全并行运行,互不干扰
3)Reduce阶段的并发ReduceTask 完全互不相干,但是他们的数据依赖于上一个阶段所有MapTask并发实例的输出
4)MapReduce编程模型只能包含一个Map阶段和一个Reduce阶段，如果用户的业务逻辑非常复杂，那就只能多个MapReduce程序串行运行

问题：
1.MapTask 是如何工作的
2.Reduce Task 是如何工作的
3.MapTask如何控制分区、排序的等
4.MapTask和ReduceTask之间如何衔接的


一个完整的MapReduce程序在分布式运行时有三类实例进程
1)MrAppMaster:负责整个程序的过程调度以及状态协调
2)MapTask	：  负责Map阶段的整个数据处理流程
3)ReduceTask:负责Reduce阶段的整个数据处理流程



Java 序列化是一个重量级序列化框架(Serializable)，一个对象被序列化后会附带额外的信息(各种校验信息，header,继承体系等)不变在网络中告诉传输
所有hadoop有自己的一套序列话机制Writable

Hadoop 序列化的特点
紧凑：高效使用存储空间
快速：读写数据的额外开销小
可扩展：随着通信协议的升级而可升级
互操作：支持多语言的交互

序列化步骤
(1)必须实现Writable接口
(2)反序列化时，需要反射调用空参构造器函数，所以必须有空参构造器
(3)重写序列化方法
(4)重写反序列化方法
(5)注意反序列化的顺序和序列化的顺序完全一致
(6)要想把结果显示到文中，需要重写toString(),可用“\t”分开，方便后续用
(7)如果需要将自定义的bean放在key中传输，则还需要实现Comparable接口，因为MapReduce框中的Shuffle过程要对key必须能排序

思考：1G的数据，启动8个MapTask，可以提高集群的并发处理能力。
那么1K的数据，也启动8个MapTask，会提高集群性能吗？
MapTask并行任务是否越多越好呢？
哪些因素影响了MapTask并行度？




